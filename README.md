# Fundamental_Feature_Engineering_1
Fundamental Techniques of Feature Engineering for Machine Learning.

1.Basic introduction.

2.Missing Data.

3.Handling Missing Data.

4.Correlation matrix. 

5.Identification of Outliers.

6.Outlier Handling methods.


Techniques Present in Feature Transformation:

Categorical features encoding,Mathematical transformation,Feature Scaling,Feature Selection.

Types of categorical features encoding:

(a) One-Hot Encoding,(b)Label/Ordinal Encoding

Mathematical transformation

(a)Logarithmic transformation,(b)Reciprocal transformation,(c)Square transformation,(d)Box-Cox transformation,(e)Yeo-Johnson transformation

Feature Scaling:

(a)Normalization(Min-Max Scaling),(b)Standardization,(c)RobustScaler Scaling

Feature Selection

(a)Pearson's Correlation Coefficient matrix, (b)Chi-square Test



Smpling-ImbalancDatasets-FeatureCreation-3


Feature Engineering part 3.

1.Different Types of Sampling Techniques(Probability Sampling,Non-Probability Sampling).

2.Techniques to Handle Imbalanced Datasets(Under-Sampling Techniques,Over-Sampling Techniques).

3.Feature Creation in Machine Learning(Polynomial Features Creation,Feature Creation from Text Dataset).

4.Model Selection in Machine Learning(No Free Lunch Theorem,Resampling,Probabilistic measures).

5.Machine Learning Pipeline(SKlearn Pipelines,Google Cloud AutoML,Azure AutoML,Auto-Sklearn,AutoKeras).
